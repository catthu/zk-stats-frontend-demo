{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from zkstats.core import (\n",
    "    setup,\n",
    ")\n",
    "from zkstats.computation import computation_to_model\n",
    "\n",
    "cwd = os.getcwd()\n",
    "\n",
    "\n",
    "# Paths to the output files\n",
    "output_dir = f\"{cwd}/out\"\n",
    "os.makedirs(output_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shared by the data provider beforehand\n",
    "data_shape = {'x': 7, 'y': 7}\n",
    "data_commitment_path = f\"{output_dir}/data_commitment.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User select the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIXME: this should be provided by users\n",
    "# selected_columns = [\"x\", \"y\"]\n",
    "selected_columns = [\"x\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User-defined Computation\n",
    "\n",
    "A computation should be of type `TComputation`. For example, the following code snippet defines a computation that computes the sum of the private data.\n",
    "\n",
    "```python\n",
    "def computation(state: State, x: list[torch.Tensor]):\n",
    "    out_0 = state.median(x[0])\n",
    "    out_1 = state.median(x[1])\n",
    "    return state.mean(torch.cat([out_0.unsqueeze(0), out_1.unsqueeze(0)]).reshape(-1,1))\n",
    "```\n",
    "\n",
    "FIXME: The following code snippet is entirely from the user. You MUST check\n",
    "1. the code only performs zkstats-related operations.\n",
    "2. the computation must not leak any information about the private data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is just a dummy computation. Replace it with user's computation\n",
    "import torch\n",
    "from zkstats.computation import State\n",
    "\n",
    "def computation(state: State, x: list[torch.Tensor]):\n",
    "    # out_0 = state.median(x[0])\n",
    "    # out_1 = state.median(x[1])\n",
    "    # # return state.mean(torch.cat([out_0.unsqueeze(0), out_1.unsqueeze(0)]).reshape(-1,1)), out_0\n",
    "    # return out_0, out_1\n",
    "    return state.mean(x[0]), state.median(x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get proof, settings, and precal_witness from the data provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "proof_path = f\"{output_dir}/model.pf\"\n",
    "settings_path = f\"{output_dir}/settings.json\"\n",
    "precal_witness_path = f\"{output_dir}/precal_witness.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the proof to ensure it is correct\n",
    "NOTE: The following section is to illustrate what should be done on the user (data consumer) side. This step is not required by the data provider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages/torch/onnx/symbolic_opset9.py:2174: FutureWarning: 'torch.onnx.symbolic_opset9._cast_Bool' is deprecated in version 2.0 and will be removed in the future. Please Avoid using this function and create a Cast node instead.\n",
      "  return fn(g, to_cast_func(g, input, False), to_cast_func(g, other, False))\n",
      "/Users/mhchia/Library/Caches/pypoetry/virtualenvs/zkstats-brXmXluj-py3.12/lib/python3.12/site-packages/torch/onnx/utils.py:1703: UserWarning: The exported ONNX model failed ONNX shape inference. The model will not be executable by the ONNX Runtime. If this is unintended and you believe there is a bug, please report an issue at https://github.com/pytorch/pytorch/issues. Error reported by strict ONNX shape inference: [ShapeInferenceError] (op_type:Where, node name: /Where_1): Y has inconsistent type tensor(float) (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/jit/serialization/export.cpp:1490.)\n",
      "  _C._check_onnx_proto(proto)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==== setting up ezkl ====\n",
      "Time setup: 0.5691819190979004 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[51.5, 46.25]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "\n",
    "\n",
    "def create_dummy(shape_info: Dict[str, int], dummy_data_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Create a dummy data file with randomized data based on the provided shape information.\n",
    "\n",
    "    Parameters:\n",
    "    - shape_info (dict): A dictionary where keys are column names and values are the number of elements (shape).\n",
    "    - dummy_data_path (str): The path to save the dummy data file.\n",
    "    \"\"\"\n",
    "    dummy_data = {}\n",
    "    for col, length in shape_info.items():\n",
    "        # Generate random data for each column\n",
    "        dummy_data[col] = np.round(np.random.uniform(0, 100, length), 1).tolist()\n",
    "\n",
    "    with open(dummy_data_path, 'w') as f:\n",
    "        json.dump(dummy_data, f)\n",
    "\n",
    "\n",
    "from zkstats.core import verifier_define_calculation, verifier_verify\n",
    "\n",
    "verifier_model_path = f\"{output_dir}/verifier_model.onnx\"\n",
    "verifier_compiled_model_path = f\"{output_dir}/verifier_model.compiled\"\n",
    "verifier_vk_path = f\"{output_dir}/verifier_model.vk\"\n",
    "verifier_pk_path = f\"{output_dir}/verifier_model.pk\"\n",
    "dummy_data_path = f\"{output_dir}/dummy_data.json\"\n",
    "sel_dummy_data_path = f\"{output_dir}/sel_dummy_data.json\"\n",
    "\n",
    "# NOTE: generate the verifier model with the `precal_witness_path` provided by the prover\n",
    "_, verifier_model = computation_to_model(computation, precal_witness_path, isProver=False)\n",
    "# Determine which srs to use with the logrows in the settings.json\n",
    "with open(settings_path, \"r\") as f:\n",
    "    settings = json.load(f)\n",
    "logrows = int(settings[\"run_args\"][\"logrows\"])\n",
    "srs_path = f'~/.ezkl/srs/kzg{logrows}.srs'\n",
    "\n",
    "# create dummy data with the same shape as the original data\n",
    "create_dummy(data_shape, dummy_data_path)\n",
    "# generate the verifier model given the dummy data and the selected columns\n",
    "verifier_define_calculation(dummy_data_path, selected_columns, sel_dummy_data_path, verifier_model, verifier_model_path)\n",
    "# generate the verification key\n",
    "setup(verifier_model_path, verifier_compiled_model_path, settings_path, verifier_vk_path, verifier_pk_path)\n",
    "# verify the proof\n",
    "verifier_verify(proof_path, settings_path, verifier_vk_path, selected_columns, data_commitment_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the file paths. You should share the following files back to the user for them to verify the proof. You **SHOULD NOT** share more files otherwise data might be leaked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model onnx:\t\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/verifier_model.onnx\n",
      "Settings:\t\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/settings.json\n",
      "Proof:\t\t\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/model.pf\n",
      "Verification key:\t /Users/mhchia/projects/work/pse/demo-next/public/assets/out/verifier_model.vk\n",
      "Srs path:\t\t ~/.ezkl/srs/kzg11.srs\n"
     ]
    }
   ],
   "source": [
    "print(\"Model onnx:\\t\\t\", verifier_model_path)\n",
    "print(\"Settings:\\t\\t\", settings_path)\n",
    "print(\"Proof:\\t\\t\\t\", proof_path)\n",
    "print(\"Verification key:\\t\", verifier_vk_path)\n",
    "print(\"Srs path:\\t\\t\", srs_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
